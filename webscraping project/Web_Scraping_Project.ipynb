{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Project (30 pts)\n",
    "\n",
    "The final step of these notebooks is to create your own project. Your project must have the following characteristics:\n",
    "\n",
    "**Project Summary:** Create a Jupyter notebook using Python code that writes out a \"self-updating website\" about an American city. Every time you run the cells in this notebook, you will get an updated website.  \n",
    "\n",
    "**Project Details:**\n",
    "\n",
    "* **To earn a C, your project must include the following:**\n",
    "  * Write Python code in this notebook that includes a function, html_output(), that concatenates an output variable and writes out its value to an HTML file - done\n",
    "  * The HTML file is a website about a city from one of the following lists:\n",
    "    * [American cities with Open Data portals](https://www.forbes.com/sites/metabrown/2017/06/30/quick-links-to-municipal-open-data-portals-for-85-us-cities/#43a0a6e02290)\n",
    "    * [Global cities with Open Data portas](https://www.opendatasoft.com/a-comprehensive-list-of-all-open-data-portals-around-the-world/)\n",
    "    * You can't use Chicago\n",
    "    * You must pick a different city than your friends/neighbors\n",
    "    * Optional: If you plan on earning extra credit on this project, you should verify that your chosen city has Open Data available in CSV format    \n",
    "  * Your website must have custom CSS styling, a title, and a header with the city name - done\n",
    "  * Your website must include a one-paragraph description of the city - done\n",
    "    * Describe the location, geography, and history of your chosen city \n",
    "    * Between 100 and 150 words\n",
    "    * Cite your sources with hyperlinks or URLs (it's okay to cite Wikipedia in this case)\n",
    "  * html_output() must call a function that scrapes weather data to give up-to-date weather information for current conditions in the selected city - done\n",
    "    * Example: \"The weather in Chicago is currently **Cloudy** with a temperature of **47** degrees Fahrenheit.\"\n",
    "    * If you can't find a weather feed for the selected city, pick one *near* your chosen city\n",
    "  * html_output() must call a function that scrapes the top (first) headline from the RSS feed of a newspaper in this city to format an up-to-date \"Top Headline\" for your chosen city - done\n",
    "    * Example: \"Blackhawks trade Ryan Hartman to Predators for first-round pick. (Chicago Tribune)\"\n",
    "    * If you can't find a newspaper in the selected city, pick one *near* your chosen city\n",
    "  * Your project code must be thoroughly explained using a combination of code comments and/or markdown cells - done\n",
    "\n",
    "\n",
    "* **To earn a B, your project must include the requirements above, as well as the following:**\n",
    "  * html_output() must call a function that scrapes and displays an image of the city directly from Wikipedia - done\n",
    "  * Instead of the weather report from the C-level requirements, html_output() must call a function that scrapes weather data to give a **descriptive**, up-to-date weather report - done\n",
    "    * Example 1: If it is 34 degrees and cloudy: “The weather today is **cold** and **dry** with **cloudy skies**. The high temperature is **34** degrees Fahrenheit.”\n",
    "    * Example 2: If it is 91 degrees and sunny: “The weather today is **hot** and **dry** with **clear skies**. The high temperature is **91** degrees.”\n",
    "    * Example 3: If it is 68 degrees and raining: “The weather today is **cool** and **wet** with **rain. Bring your umbrella!** The high temperature is **68** degrees.”\n",
    "    * Brainstorm other adjectives you may consider using, and customize the report to your own style/prefernces\n",
    "    * Also incorporate wind and humidity into your weather report    \n",
    "\n",
    "\n",
    "* **To earn an A, your project must include the requirements above, as well as the following:**\n",
    "  * Instead of a single \"Top Headline,\" html_output() must call a function that scrapes three different random headlines from the RSS feed of a newspaper in this city to format an up-to-date set of \"News Alerts\" for your chosen city - done\n",
    "    * If you can't find a newspaper in the selected city, pick one *near* your chosen city\n",
    "  * Change the background color generated for your webpage page based on the temperature in the weather report. Use hex colors such as \"#FF0000\" instead of \"RGB(255,0,0)\" or a color name such as \"red\".\n",
    "    * Below zero: Purple\n",
    "    * Below 32: Blue\n",
    "    * Below 40: Cyan\n",
    "    * Below 50: Green\n",
    "    * Below 60: Yellow\n",
    "    * Below 70: Light Orange\n",
    "    * Below 80: Dark Orange\n",
    "    * Below 90: Red\n",
    "    * Above 90: Dark Red\n",
    "\n",
    "\n",
    "* **To earn Extra Credit, you can pick any (or all) of these optional enhancements to incorporate into your page. The number of points earned will depend on which enhancement(s) you pick and the quality of your work:**\n",
    "  * html_output() calls a function that gets up-to-date data from a CSV file\n",
    "    * That data must be formatted and displayed on your website\n",
    "    * The CSV file must be loaded from a URL (this way, the data gets updated when you re-run the notebook)\n",
    "    * For example, if you have a CSV with car thefts, you could include the time, location, and make/model of the most recent 10 car thefts in your city\n",
    "  * Your Open Data output is turned into a graph or chart and displayed on the webpage as an image\n",
    "    * For example, you might include a bar chart that shows how many traffic tickets were issued in your city each day for the past 7 days\n",
    "  * Your page includes other kinds of interesting/relevant scraped data not listed in the above requirements or other kinds of JavaScipt functionality that improves your page  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project Code:\n",
    "\n",
    "Write the code for your project below. You can use as many code/markdown cells as you need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<?xml-stylesheet href=\"latest_ob.xsl\" type=\"text/xsl\"?>\n",
      "<current_observation version=\"1.0\" xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:noNamespaceSchemaLocation=\"http://www.weather.gov/view/current_observation.xsd\">\n",
      " <credit>\n",
      "  NOAA's National Weather Service\n",
      " </credit>\n",
      " <credit_URL>\n",
      "  http://weather.gov/\n",
      " </credit_URL>\n",
      " <image>\n",
      "  <url>\n",
      "   http://weather.gov/images/xml_logo.gif\n",
      "  </url>\n",
      "  <title>\n",
      "   NOAA's National Weather Service\n",
      "  </title>\n",
      "  <link>\n",
      "   http://weather.gov\n",
      "  </link>\n",
      " </image>\n",
      " <suggested_pickup>\n",
      "  15 minutes after the hour\n",
      " </suggested_pickup>\n",
      " <suggested_pickup_period>\n",
      "  60\n",
      " </suggested_pickup_period>\n",
      " <location>\n",
      "  Austin-Bergstrom International Airport, TX\n",
      " </location>\n",
      " <station_id>\n",
      "  KAUS\n",
      " </station_id>\n",
      " <latitude>\n",
      "  30.18304\n",
      " </latitude>\n",
      " <longitude>\n",
      "  -97.67987\n",
      " </longitude>\n",
      " <observation_time>\n",
      "  Last Updated on Apr 25 2019, 8:53 pm CDT\n",
      " </observation_time>\n",
      " <observation_time_rfc822>\n",
      "  Thu, 25 Apr 2019 20:53:00 -0500\n",
      " </observation_time_rfc822>\n",
      " <weather>\n",
      "  Fair\n",
      " </weather>\n",
      " <temperature_string>\n",
      "  71.0 F (21.7 C)\n",
      " </temperature_string>\n",
      " <temp_f>\n",
      "  71.0\n",
      " </temp_f>\n",
      " <temp_c>\n",
      "  21.7\n",
      " </temp_c>\n",
      " <relative_humidity>\n",
      "  61\n",
      " </relative_humidity>\n",
      " <wind_string>\n",
      "  North at 4.6 MPH (4 KT)\n",
      " </wind_string>\n",
      " <wind_dir>\n",
      "  North\n",
      " </wind_dir>\n",
      " <wind_degrees>\n",
      "  360\n",
      " </wind_degrees>\n",
      " <wind_mph>\n",
      "  4.6\n",
      " </wind_mph>\n",
      " <wind_kt>\n",
      "  4\n",
      " </wind_kt>\n",
      " <pressure_string>\n",
      "  1013.4 mb\n",
      " </pressure_string>\n",
      " <pressure_mb>\n",
      "  1013.4\n",
      " </pressure_mb>\n",
      " <pressure_in>\n",
      "  29.94\n",
      " </pressure_in>\n",
      " <dewpoint_string>\n",
      "  57.0 F (13.9 C)\n",
      " </dewpoint_string>\n",
      " <dewpoint_f>\n",
      "  57.0\n",
      " </dewpoint_f>\n",
      " <dewpoint_c>\n",
      "  13.9\n",
      " </dewpoint_c>\n",
      " <visibility_mi>\n",
      "  10.00\n",
      " </visibility_mi>\n",
      " <icon_url_base>\n",
      "  http://forecast.weather.gov/images/wtf/small/\n",
      " </icon_url_base>\n",
      " <two_day_history_url>\n",
      "  http://www.weather.gov/data/obhistory/KAUS.html\n",
      " </two_day_history_url>\n",
      " <icon_url_name>\n",
      "  nskc.png\n",
      " </icon_url_name>\n",
      " <ob_url>\n",
      "  http://www.weather.gov/data/METAR/KAUS.1.txt\n",
      " </ob_url>\n",
      " <disclaimer_url>\n",
      "  http://weather.gov/disclaimer.html\n",
      " </disclaimer_url>\n",
      " <copyright_url>\n",
      "  http://weather.gov/disclaimer.html\n",
      " </copyright_url>\n",
      " <privacy_policy_url>\n",
      "  http://weather.gov/notice.html\n",
      " </privacy_policy_url>\n",
      "</current_observation>\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "from urllib.request import urlopen\n",
    "\n",
    "xml_page = urlopen(\"http://w1.weather.gov/xml/current_obs/KAUS.xml\")   # Opens whatever page we are requesting\n",
    "bs_obj = BeautifulSoup(xml_page, 'xml')\n",
    "\n",
    "print(bs_obj.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  \n",
    "from urllib.request import urlopen\n",
    "\n",
    "# open Austin Statesman's local news XML files\n",
    "xml_page = urlopen(\"https://www.statesman.com/news/local?template=rss&mime=xml\")   # Opens whatever page we are requesting\n",
    "bs_obj = BeautifulSoup(xml_page, 'xml')\n",
    "\n",
    "# find all news headlines from RSS feed\n",
    "headlines = bs_obj.find_all('title')\n",
    "headlines = [story.getText() for story in headlines]\n",
    "\n",
    "# remove garbage\n",
    "headlines = headlines[1:]\n",
    "\n",
    "# background\n",
    "temp = tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'temp_f')\n",
    "temp = float(temp)\n",
    "if temp >= 70:\n",
    "    background = \"#FFA500\"\n",
    "elif temp >= 50:\n",
    "    background = \"#00FF00\"\n",
    "else:\n",
    "    background = \"#0000FF\"\n",
    "\n",
    "# takes a website and a tag and finds whatever data is under that tag\n",
    "def tag_extractor(url, tag):    \n",
    "    from bs4 import BeautifulSoup  \n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    xml_page = urlopen(url)   # opens whatever page we are requesting\n",
    "    bs_obj = BeautifulSoup(xml_page, 'xml')\n",
    "    \n",
    "    return bs_obj.find(tag).getText()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# extract 3 random headlines and concatenate a message including these 3 headlines\n",
    "def random_headline(headline_list):\n",
    "    length = len(headline_list)\n",
    "    # pick a random headline\n",
    "    choice = np.random.choice(length,3)\n",
    "    \n",
    "    # pick headlines\n",
    "    headline1 = headline_list[choice[0]]    \n",
    "    headline2 = headline_list[choice[1]]\n",
    "    headline3 = headline_list[choice[2]]\n",
    "    \n",
    "    # concatenate message\n",
    "    output = headline1\n",
    "    output += \" (Austin-American Statesman). \"\n",
    "    output += headline2\n",
    "    output += \" (Austin-American Statesman). \"\n",
    "    output += headline3\n",
    "    output += \" (Austin-American Statesman). \"\n",
    "    \n",
    "    return(output)\n",
    "\n",
    "# enter the url from a wikipedia page and find the url of the 1st image on that page\n",
    "def get_image_url(article_url):\n",
    "    html_page = urlopen(\"http://en.wikipedia.org\"+article_url)   #opens whatever page we are requesting\n",
    "    bs_obj = BeautifulSoup(html_page, 'html.parser')    #Saves the html in a Beautiful Soup object\n",
    "    #The next line finds specific HTML elements in the page we opened - notice the familiar tags and properties\n",
    "    try:\n",
    "        image_url = bs_obj.find(\"meta\",{\"property\":\"og:image\"}).attrs['content']\n",
    "    except AttributeError:\n",
    "        image_url = False\n",
    "    return image_url\n",
    "\n",
    "# display an image from wikipedia given the url\n",
    "def return_image(wiki_url,image_width):\n",
    "    import requests\n",
    "    from IPython.display import Image, display\n",
    "    \n",
    "    if get_image_url(wiki_url) != False:\n",
    "        img=get_image_url(wiki_url)\n",
    "        url_to_file = requests.get(img).content\n",
    "        extension = img.split('.')[-1]\n",
    "        name = \"output/output_image.\" + extension\n",
    "        # create file\n",
    "        with open(name, 'wb') as image:\n",
    "            image.write(url_to_file)\n",
    "        # display image\n",
    "        display(Image(filename=name,width=image_width))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Check your 'Webscraping Project' folder to find the new HTML file. ***\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "# writes the HTML for the website\n",
    "def html_output():    \n",
    "    output_string = \"\"\"\n",
    "    <html>\n",
    "    <head>\n",
    "    <meta http-equiv=\"refresh\" content=\"3600\">\n",
    "        <style>\n",
    "            body {\n",
    "                background-color: background; \n",
    "                text-align: center;\n",
    "                font-family: Palatino, \"Palatino Linotype\", \"Palatino LT STD\", \"Book Antiqua\", Georgia, serif;\n",
    "            }\n",
    "            \n",
    "            h1{\n",
    "                font-size: 50 \n",
    "            }\n",
    "        \n",
    "            h2{\n",
    "                font-size: 25\n",
    "            }\n",
    "            \n",
    "            p{\n",
    "                font-size: 20\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "\n",
    "    <body>\n",
    "    <h1>Austin, Texas</h1>\n",
    "    <h2>A Background</h2>\n",
    "    <p>\n",
    "    \"\"\"\n",
    "\n",
    "    # information citation: https://en.wikipedia.org/wiki/Austin,_Texas\n",
    "    # background on Austin\n",
    "    # concatenate string\n",
    "    output_string += \"Austin is located in central Texas and is also the state capital of Texas. The land is a flat prairie near the Colorado River. It has the fastest growing population of any city in the United States with over 300,000 inhabitants. The location itself is defined by its live music and tech industry. Of course, like most cities, it started from humble beginnings when in 1837, United States Vice President Mirabeau B. Lamar, happened to be on a buffalo-hunting expedition when he stated that the land where Austin is now would become the Texas state capital. Later, in 1839, the land was deemed the state capital and named Austin, after the founder of Texas, Stephen F. Austin.\"\n",
    "\n",
    "    output_string += \"\"\"\n",
    "    </p>\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    <h2>Weather Report</h2>\n",
    "    <p> The weather is\n",
    "    \"\"\"\n",
    "    \n",
    "    # extract weather\n",
    "    weather = tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'weather')\n",
    "    \n",
    "    # make lowercase\n",
    "    weather = (weather.lower())\n",
    "    \n",
    "    if(weather == \"light rain\"):\n",
    "        weather = \"drizzling\"\n",
    "    \n",
    "    # add on weather\n",
    "    output_string += weather\n",
    "    \n",
    "    output_string += \", \"\n",
    "    \n",
    "    # extract wind speed\n",
    "    wind_speed = tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'wind_mph')\n",
    "    \n",
    "    # turn into integer\n",
    "    wind_speed = float(wind_speed)\n",
    "    \n",
    "    # describe the wind speed\n",
    "    if (wind_speed >= 25):\n",
    "        output_string += \" windy\"\n",
    "    \n",
    "    elif (wind_speed >= 15):\n",
    "        output_string += \" breezy\"\n",
    "    \n",
    "    else:\n",
    "        output_string += \" not windy\"\n",
    "    \n",
    "    output_string += \", and\"\n",
    "    \n",
    "    # extract humidity\n",
    "    humidity = tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'relative_humidity')\n",
    "    \n",
    "    # turn into integer\n",
    "    humidity = float(humidity)\n",
    "    \n",
    "    # describe the humidity\n",
    "    if (humidity >= 60):\n",
    "        output_string += \" humid\"\n",
    "    elif (humidity >= 30):\n",
    "        output_string += \" neither humid nor dry\"\n",
    "    else:\n",
    "        output_string += \" dry\"\n",
    "    \n",
    "    output_string += \". The temperature is \"\n",
    "    \n",
    "    # extract temperature\n",
    "    output_string += tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'temp_f')\n",
    "    \n",
    "    output_string += \" degrees fahrenheit, the windspeed is \"\n",
    "    \n",
    "     # turn back into string\n",
    "    wind_speed = str(wind_speed)\n",
    "    \n",
    "    # add on wind speed\n",
    "    output_string += wind_speed\n",
    "    \n",
    "    output_string += \" mph, and the visibility is \"\n",
    "    \n",
    "    # extract visibility\n",
    "    output_string += tag_extractor('http://w1.weather.gov/xml/current_obs/KAUS.xml', 'visibility_mi')\n",
    "    \n",
    "    output_string += \"\"\"\n",
    "    miles.\n",
    "    </p>\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    <h2>News Report</h2>\n",
    "    <p>\n",
    "    \"\"\"\n",
    "    \n",
    "    # 3 random news stories\n",
    "    # concatenate message\n",
    "    output_string += random_headline(headlines)\n",
    "\n",
    "    output_string += \"\"\"\n",
    "    </p>\n",
    "    \n",
    "    <br>\n",
    "    \n",
    "    <img src = \"output_image.jpg\" width = 500>\n",
    "\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # send to HTML file\n",
    "    html_file= open(\"output/Austin, Texas.html\",\"w\")\n",
    "    html_file.write(output_string)\n",
    "    html_file.close()\n",
    "    \n",
    "# now call the function: \n",
    "html_output()\n",
    "print(\"*** Check your 'Webscraping Project' folder to find the new HTML file. ***\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
